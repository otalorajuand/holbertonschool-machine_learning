# Dimensionality Reduction

> Dimensionality reduction is a technique for compressing our data for various purposes like plotting or to have more compact models. In this project we explore the most known dimensionality reduction algorithms: PCA and T-sne. 

At the end of this project I was able to solve these conceptual questions:

* What is eigendecomposition?
* What is singular value decomposition?
* What is the difference between eig and svd?
* What is dimensionality reduction and what are its purposes?
* What is principal components analysis (PCA)?
* What is t-distributed stochastic neighbor embedding (t-SNE)?
* What is a manifold?
* What is the difference between linear and non-linear dimensionality reduction?
* Which techniques are linear/non-linear?

## Tasks :heavy_check_mark:

| Filename | Task |
| ------ | ------------------------------------------------- | 
| [0-pca.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/dimensionality_reduction/0-pca.py)| Write a function that performs PCA on a dataset. | 
| [1-pca.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/dimensionality_reduction/1-pca.py)| Write a function that performs PCA on a dataset. | 
| [2-P_init.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/dimensionality_reduction/2-P_init.py)| Write a function that initializes all variables required to calculate the P affinities in t-SNE. | 
| [3-entropy.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/dimensionality_reduction/3-entropy.py)| Write a function that calculates the Shannon entropy and P affinities relative to a data point. | 


### Try It On Your Machine :computer:
```bash
git clone https://github.com/otalorajuand/holbertonschool-machine_learning.git
cd unsupervised_learning/dimensionality_reduction
```