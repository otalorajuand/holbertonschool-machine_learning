# Autoencoders

> Autoencoders are a very useful unsupervised technique for understanding your data in a compressed or latent space. Regular autoencoder allow us to compress and also to segment our data. Variational autoencoders, on the other hand allow us to generate data. In this project, we implement both models and understand how they work underneath. 

At the end of this project I was able to solve these conceptual questions:

* What is an autoencoder?
* What is latent space?
* What is a bottleneck?
* What is a sparse autoencoder?
* What is a convolutional autoencoder?
* What is a generative model?
* What is a variational autoencoder?
* What is the Kullback-Leibler divergence?

## Tasks :heavy_check_mark:

| Filename | Task |
| ------ | ------------------------------------------------- | 
| [0-vanilla.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/autoencoders/0-vanilla.py)| Write a function that creates an autoencoder. | 
| [1-sparse.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/autoencoders/1-sparse.py)| Write a function that creates a sparse autoencoder. | 
| [2-convolutional.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/autoencoders/2-convolutional.py)| Write a function that creates a convolutional autoencoder. | 
| [3-variational.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/unsupervised_learning/autoencoders/3-variational.py)| Write a function that creates a variational autoencoder. | 



### Try It On Your Machine :computer:
```bash
git clone https://github.com/otalorajuand/holbertonschool-machine_learning.git
cd unsupervised_learning/autoencoders
```