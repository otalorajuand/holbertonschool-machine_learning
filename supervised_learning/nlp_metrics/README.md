# Natural Language Processing - Evaluation Metrics

>  The project's primary objectives are outlined, which include addressing several conceptual questions related to NLP applications and evaluation metrics. These questions cover a range of topics, from understanding the applications of NLP to exploring specific evaluation metrics like BLEU score, ROUGE score, and perplexity. 

At the end of this project I was able to solve these conceptual questions:

* What are the applications of natural language processing?
* What is a BLEU score?
* What is a ROUGE score?
* What is perplexity?
* When should you use one evaluation metric over another?


## Tasks :heavy_check_mark:

| Filename | Task |
| ------ | ------------------------------------------------- | 
| [0-uni_bleu.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/nlp_metrics/0-uni_bleu.py)| Write the function that calculates the unigram BLEU score for a sentence. | 
| [1-ngram_bleu.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/nlp_metrics/1-ngram_bleu.py)| Write the function that calculates the n-gram BLEU score for a sentence. | 
| [2-cumulative_bleu.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/nlp_metrics/2-cumulative_bleu.py)| Write the function that calculates the cumulative n-gram BLEU score for a sentence. | 



### Try It On Your Machine :computer:
```bash
git clone https://github.com/otalorajuand/holbertonschool-machine_learning.git
cd supervised_learning/nlp_metrics
```