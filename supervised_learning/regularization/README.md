# Regularization

> Regularization is a technique that allow us to reduce the variance of the model and consequently reduce the test error.

At the end of this project I was able to solve these conceptual questions:

* What is regularization? What is its purpose?
* What is are L1 and L2 regularization? What is the difference between the two methods?
* What is dropout?
* What is early stopping?
* What is data augmentation?
* How do you implement the above regularization methods in Numpy? Tensorflow?
* What are the pros and cons of the above regularization methods?

## Tasks :heavy_check_mark:

| Filename | Task |
| ------ | ------------------------------------------------- | 
| [0-l2_reg_cost.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/0-l2_reg_cost.py)| Write a function that calculates the cost of a neural network with L2 regularization.| 
| [1-l2_reg_gradient_descent.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/1-l2_reg_gradient_descent.py)| Write a function that updates the weights and biases of a neural network using gradient descent with L2 regularization.| 
| [2-l2_reg_cost.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/2-l2_reg_cost.py)| Write the function that calculates the cost of a neural network with L2 regularization. | 
| [3-l2_reg_create_layer.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/3-l2_reg_create_layer.py)| Write a function that creates a tensorflow layer that includes L2 regularization. | 
| [4-dropout_forward_prop.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/4-dropout_forward_prop.py)| Write a function that conducts forward propagation using Dropout. | 
| [5-dropout_gradient_descent.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/5-dropout_gradient_descent.py)| Write a function that updates the weights of a neural network with Dropout regularization using gradient descent. | 
| [6-dropout_create_layer.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/6-dropout_create_layer.py)| Write a function that creates a layer of a neural network using dropout. | 
| [7-early_stopping.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/supervised_learning/regularization/7-early_stopping.py)| Write the function that determines if you should stop gradient descent early. | 



### Try It On Your Machine :computer:
```bash
git clone https://github.com/otalorajuand/holbertonschool-machine_learning.git
cd supervised_learning/regularization
```
