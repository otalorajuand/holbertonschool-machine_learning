# Temporal Difference

> The "Temporal Difference" project focuses on implementing reinforcement learning algorithms (Monte Carlo, TD(λ), SARSA(λ)) to train an agent in OpenAI's FrozenLake environment. It involves coding tasks, learning objectives, resource references, and specific code requirements. The goal is to create well-documented Python code adhering to guidelines to pass test cases.

At the end of this project I was able to solve these conceptual questions:

* What is Monte Carlo?
* What is Temporal Difference?
* What is bootstrapping?
* What is n-step temporal difference?
* What is TD(λ)?
* What is an eligibility trace?
* What is SARSA? SARSA(λ)? SARSAMAX?
* What is ‘on-policy’ vs ‘off-policy’?

## Tasks :heavy_check_mark:

| Filename | Task |
| ------ | ------------------------------------------------- | 
| [0-monte_carlo.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/reinforcement_learning/temporal_difference/0-monte_carlo.py)| Generates episodes, updates values using rewards to improve learning in reinforcement environments. | 
| [1-td_lambtha.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/reinforcement_learning/temporal_difference/1-td_lambtha.py)| Applies TD(λ) algorithm, updating value estimates using eligibility traces in RL environments. | 
| [2-sarsa_lambtha.py](https://github.com/otalorajuand/holbertonschool-machine_learning/blob/main/reinforcement_learning/temporal_difference/2-sarsa_lambtha.py)| Performs SARSA(λ) algorithm to update Q-table in reinforcement learning environments. | 

### Try It On Your Machine :computer:
```bash
git clone https://github.com/otalorajuand/holbertonschool-machine_learning.git
cd reinforcement_learning/temporal_difference
```
